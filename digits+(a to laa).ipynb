{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff7df87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import glob\n",
    "\n",
    "# Parent folder path containing the digit and alphabet folders\n",
    "parent_folder_path = \"C:/Users/Rumana/Desktop/HandWritten_Kannada/captured_images\"\n",
    "\n",
    "# Define the labels for digits and alphabets\n",
    "digit_labels = list(range(10))\n",
    "alphabet_labels = ['a', 'aaa', 'e', 'eee', 'u', 'uuu', 'ru', 'ye', 'yeee', 'ai', 'o', 'ooo', 'oww', 'am', 'aha','ka','kha','ga','gha','1_nya','ca','cha','ja','jha','2_nya','ta','ttha','dda','ddha','nna','tha','thaa','da','dha','na','pa','pha','ba','bha','ma','ya','ra','la','va','shea','sa','ha','laa']\n",
    "\n",
    "\n",
    "# Define the header for the CSV file\n",
    "header = [\"label\"]\n",
    "for i in range(0, 784):\n",
    "    header.append(\"pixel\" + str(i))\n",
    "\n",
    "with open('kannada_full_data.csv', 'a') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "\n",
    "# Load the captured images and preprocess them\n",
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "# Process digits and alphabets\n",
    "for label in digit_labels + alphabet_labels:\n",
    "    dirList = glob.glob(os.path.join(parent_folder_path, str(label), \"*.png\"))\n",
    "\n",
    "    for img_path in dirList:\n",
    "        im = cv2.imread(img_path)\n",
    "        im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "        im_gray = cv2.GaussianBlur(im_gray, (15, 15), 0)\n",
    "        roi = cv2.resize(im_gray, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        data = []\n",
    "        data.append(label)\n",
    "\n",
    "        # Flatten the image data\n",
    "        flattened_image = roi.flatten() / 255.0\n",
    "        data.extend(flattened_image)\n",
    "\n",
    "        train_x.append(flattened_image)\n",
    "        train_y.append(label)\n",
    "\n",
    "        with open('kannada_full_data.csv', 'a') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(data)\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "\n",
    "# Save the training dataset as numpy arrays\n",
    "np.save(\"C:/Users/Rumana/Desktop/HandWritten_Kannada/captured_images/train_X.npy\", train_x)\n",
    "np.save(\"C:/Users/Rumana/Desktop/HandWritten_Kannada/captured_images/train_Y.npy\", train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ad24546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>ru</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>ai</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3345</th>\n",
       "      <td>jha</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2743</th>\n",
       "      <td>ga</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2660</th>\n",
       "      <td>kha</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4534</th>\n",
       "      <td>pa</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4528</th>\n",
       "      <td>pa</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4260</th>\n",
       "      <td>da</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3137</th>\n",
       "      <td>cha</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5506 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label pixel0 pixel1 pixel2 pixel3 pixel4 pixel5 pixel6 pixel7 pixel8  \\\n",
       "1676    ru    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1964    ai    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "45       0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3345   jha    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2743    ga    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "2660   kha    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4534    pa    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4528    pa    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4260    da    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3137   cha    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "      ... pixel774 pixel775 pixel776 pixel777 pixel778 pixel779 pixel780  \\\n",
       "1676  ...      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1964  ...      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "45    ...      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3345  ...      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2743  ...      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "...   ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "2660  ...      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4534  ...      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4528  ...      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4260  ...      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3137  ...      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "     pixel781 pixel782 pixel783  \n",
       "1676      0.0      0.0      0.0  \n",
       "1964      0.0      0.0      0.0  \n",
       "45        0.0      0.0      0.0  \n",
       "3345      0.0      0.0      0.0  \n",
       "2743      0.0      0.0      0.0  \n",
       "...       ...      ...      ...  \n",
       "2660      0.0      0.0      0.0  \n",
       "4534      0.0      0.0      0.0  \n",
       "4528      0.0      0.0      0.0  \n",
       "4260      0.0      0.0      0.0  \n",
       "3137      0.0      0.0      0.0  \n",
       "\n",
       "[5506 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "data  =pd.read_csv('kannada_full_data.csv',dtype=str)\n",
    "# Identify duplicates\n",
    "duplicates = data[data.duplicated()]\n",
    "\n",
    "# Remove duplicates\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "# Shuffle the dataset\n",
    "data = shuffle(data)\n",
    "\n",
    "data=shuffle(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b681b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = data.drop([\"label\"],axis=1)\n",
    "Y = data[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a810e548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_shuffled_images(images, labels, rows, cols):\n",
    "    # Combine images and labels into a single array for shuffling\n",
    "    combined_data = list(zip(images, labels))\n",
    "    np.random.shuffle(combined_data)\n",
    "    \n",
    "    # Unpack the shuffled data\n",
    "    shuffled_images, shuffled_labels = zip(*combined_data)\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(10, 10))\n",
    "\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            idx = i * cols + j\n",
    "            img = shuffled_images[idx].reshape(28, 28).astype(float)  # Convert to float\n",
    "            label = shuffled_labels[idx]\n",
    "\n",
    "            axes[i, j].imshow(img, cmap='gray')\n",
    "            axes[i, j].set_title(f\"Label: {label}\")\n",
    "            axes[i, j].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Specify the number of rows and columns for the grid\n",
    "num_rows = 3\n",
    "num_cols = 4\n",
    "\n",
    "# Assuming X is a DataFrame containing image data and Y is a Series containing labels\n",
    "# You can adapt this based on your specific data structure\n",
    "# Display a shuffled set of images from your dataset\n",
    "display_shuffled_images(X.values, Y, num_rows, num_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "829a33b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Load the training dataset\n",
    "train_x = np.load(\"C:/Users/Rumana/Desktop/HandWritten_Kannada/captured_images/train_X.npy\")\n",
    "train_y = np.load(\"C:/Users/Rumana/Desktop/HandWritten_Kannada/captured_images/train_Y.npy\")\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19aa266b",
   "metadata": {},
   "source": [
    "# support vector classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b73149f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', random_state=6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', random_state=6)\n",
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a504177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/svm(digits+a-laa)']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(svm_model,\"model/svm(digits+a-laa)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "952c57f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.98%\n",
      "Precision: 73.36%\n",
      "Recall: 72.98%\n",
      "F1 Score: 72.38%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import joblib\n",
    "\n",
    "# Load the trained SVC model\n",
    "svc_model = joblib.load(\"model/svm(digits+a-laa)\")\n",
    "\n",
    "# Assuming X_test_imputed and test_y are correctly loaded and preprocessed\n",
    "predictions = svc_model.predict(X_test)\n",
    "\n",
    "# Evaluate metrics\n",
    "accuracy = accuracy_score(y_test, predictions) * 100\n",
    "precision = precision_score(y_test, predictions, average='weighted') * 100\n",
    "recall = recall_score(y_test, predictions, average='weighted') * 100\n",
    "f1 = f1_score(y_test, predictions, average='weighted') * 100\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}%\")\n",
    "print(f\"Recall: {recall:.2f}%\")\n",
    "print(f\"F1 Score: {f1:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400283e2",
   "metadata": {},
   "source": [
    "# K-nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c43ea890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/knn(digits+a-laa)']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import joblib\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(knn,\"model/knn(digits+a-laa)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe8d9705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.05%\n",
      "Precision: 74.83%\n",
      "Recall: 70.05%\n",
      "F1 Score: 71.12%\n"
     ]
    }
   ],
   "source": [
    "knn_model = joblib.load(\"model/knn(digits+a-laa)\")\n",
    "\n",
    "# Assuming X_test_imputed and test_y are correctly loaded and preprocessed\n",
    "predictions = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate metrics\n",
    "accuracy = accuracy_score(y_test, predictions) * 100\n",
    "precision = precision_score(y_test, predictions, average='weighted') * 100\n",
    "recall = recall_score(y_test, predictions, average='weighted') * 100\n",
    "f1 = f1_score(y_test, predictions, average='weighted') * 100\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}%\")\n",
    "print(f\"Recall: {recall:.2f}%\")\n",
    "print(f\"F1 Score: {f1:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb3fd64",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3fff8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade tensorflow\n",
    "#!pip install --upgrade protobuf\n",
    "\n",
    "\n",
    "#!pip install tensorflow==2.7.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e670e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "148/148 [==============================] - 4s 22ms/step - loss: 3.2270 - accuracy: 0.1930 - val_loss: 2.0973 - val_accuracy: 0.4149\n",
      "Epoch 2/80\n",
      "148/148 [==============================] - 3s 22ms/step - loss: 1.3907 - accuracy: 0.6066 - val_loss: 1.1077 - val_accuracy: 0.6864\n",
      "Epoch 3/80\n",
      "148/148 [==============================] - 3s 22ms/step - loss: 0.8872 - accuracy: 0.7352 - val_loss: 0.8508 - val_accuracy: 0.7247\n",
      "Epoch 4/80\n",
      "148/148 [==============================] - 3s 17ms/step - loss: 0.6476 - accuracy: 0.8045 - val_loss: 0.7641 - val_accuracy: 0.7820\n",
      "Epoch 5/80\n",
      "148/148 [==============================] - 2s 17ms/step - loss: 0.4872 - accuracy: 0.8519 - val_loss: 0.6077 - val_accuracy: 0.8011\n",
      "Epoch 6/80\n",
      "148/148 [==============================] - 2s 17ms/step - loss: 0.4049 - accuracy: 0.8718 - val_loss: 0.5883 - val_accuracy: 0.8126\n",
      "Epoch 7/80\n",
      "148/148 [==============================] - 2s 16ms/step - loss: 0.3242 - accuracy: 0.8973 - val_loss: 0.5471 - val_accuracy: 0.8451\n",
      "Epoch 8/80\n",
      "148/148 [==============================] - 2s 16ms/step - loss: 0.2675 - accuracy: 0.9167 - val_loss: 0.5355 - val_accuracy: 0.8298\n",
      "Epoch 9/80\n",
      "148/148 [==============================] - 2s 16ms/step - loss: 0.2052 - accuracy: 0.9345 - val_loss: 0.5267 - val_accuracy: 0.8432\n",
      "Epoch 10/80\n",
      "148/148 [==============================] - 2s 17ms/step - loss: 0.2103 - accuracy: 0.9335 - val_loss: 0.7889 - val_accuracy: 0.7839\n",
      "Epoch 11/80\n",
      "148/148 [==============================] - 3s 17ms/step - loss: 0.3693 - accuracy: 0.8965 - val_loss: 0.4526 - val_accuracy: 0.8757\n",
      "Epoch 12/80\n",
      "148/148 [==============================] - 3s 20ms/step - loss: 0.1502 - accuracy: 0.9530 - val_loss: 0.5285 - val_accuracy: 0.8470\n",
      "Epoch 13/80\n",
      "148/148 [==============================] - 3s 23ms/step - loss: 0.1173 - accuracy: 0.9654 - val_loss: 0.4848 - val_accuracy: 0.8662\n",
      "Epoch 14/80\n",
      "148/148 [==============================] - 3s 20ms/step - loss: 0.0902 - accuracy: 0.9760 - val_loss: 0.4845 - val_accuracy: 0.8719\n",
      "Epoch 15/80\n",
      "148/148 [==============================] - 3s 21ms/step - loss: 0.0873 - accuracy: 0.9756 - val_loss: 0.5188 - val_accuracy: 0.8623\n",
      "Epoch 16/80\n",
      "148/148 [==============================] - 5s 32ms/step - loss: 0.0981 - accuracy: 0.9722 - val_loss: 0.5982 - val_accuracy: 0.8337\n",
      "Epoch 17/80\n",
      "148/148 [==============================] - 3s 24ms/step - loss: 0.0740 - accuracy: 0.9787 - val_loss: 0.5066 - val_accuracy: 0.8700\n",
      "Epoch 18/80\n",
      "148/148 [==============================] - 4s 24ms/step - loss: 0.0431 - accuracy: 0.9892 - val_loss: 0.4490 - val_accuracy: 0.8834\n",
      "Epoch 19/80\n",
      "148/148 [==============================] - 3s 23ms/step - loss: 0.0447 - accuracy: 0.9896 - val_loss: 0.5365 - val_accuracy: 0.8776\n",
      "Epoch 20/80\n",
      "148/148 [==============================] - 3s 23ms/step - loss: 0.0439 - accuracy: 0.9883 - val_loss: 0.5823 - val_accuracy: 0.8662\n",
      "Epoch 21/80\n",
      "148/148 [==============================] - 3s 19ms/step - loss: 0.0664 - accuracy: 0.9777 - val_loss: 0.6255 - val_accuracy: 0.8623\n",
      "Epoch 22/80\n",
      "148/148 [==============================] - 3s 19ms/step - loss: 0.1338 - accuracy: 0.9586 - val_loss: 0.6321 - val_accuracy: 0.8681\n",
      "Epoch 23/80\n",
      "148/148 [==============================] - 3s 18ms/step - loss: 0.0516 - accuracy: 0.9862 - val_loss: 0.5670 - val_accuracy: 0.8815\n",
      "Epoch 24/80\n",
      "148/148 [==============================] - 3s 18ms/step - loss: 0.0315 - accuracy: 0.9923 - val_loss: 0.6196 - val_accuracy: 0.8642\n",
      "Epoch 25/80\n",
      "148/148 [==============================] - 3s 20ms/step - loss: 0.0714 - accuracy: 0.9796 - val_loss: 0.5860 - val_accuracy: 0.8662\n",
      "Epoch 26/80\n",
      "148/148 [==============================] - 3s 22ms/step - loss: 0.0737 - accuracy: 0.9773 - val_loss: 0.6026 - val_accuracy: 0.8604\n",
      "Epoch 27/80\n",
      "148/148 [==============================] - 3s 21ms/step - loss: 0.0188 - accuracy: 0.9966 - val_loss: 0.4890 - val_accuracy: 0.8834\n",
      "Epoch 28/80\n",
      "148/148 [==============================] - 3s 20ms/step - loss: 0.0097 - accuracy: 0.9985 - val_loss: 0.5609 - val_accuracy: 0.8891\n",
      "Epoch 29/80\n",
      "148/148 [==============================] - 4s 27ms/step - loss: 0.0093 - accuracy: 0.9983 - val_loss: 0.5507 - val_accuracy: 0.8795\n",
      "Epoch 30/80\n",
      "148/148 [==============================] - 3s 21ms/step - loss: 0.0068 - accuracy: 0.9989 - val_loss: 0.5462 - val_accuracy: 0.8967\n",
      "Epoch 31/80\n",
      "148/148 [==============================] - 3s 22ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.5804 - val_accuracy: 0.8948\n",
      "Epoch 32/80\n",
      "148/148 [==============================] - 3s 21ms/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.5639 - val_accuracy: 0.8891\n",
      "Epoch 33/80\n",
      "148/148 [==============================] - 3s 19ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.5923 - val_accuracy: 0.8872\n",
      "Epoch 34/80\n",
      "148/148 [==============================] - 3s 19ms/step - loss: 0.0181 - accuracy: 0.9951 - val_loss: 0.9142 - val_accuracy: 0.8317\n",
      "Epoch 35/80\n",
      "148/148 [==============================] - 3s 21ms/step - loss: 0.1789 - accuracy: 0.9447 - val_loss: 0.6133 - val_accuracy: 0.8585\n",
      "Epoch 36/80\n",
      "148/148 [==============================] - 3s 23ms/step - loss: 0.0600 - accuracy: 0.9836 - val_loss: 0.5285 - val_accuracy: 0.8872\n",
      "Epoch 37/80\n",
      "148/148 [==============================] - 3s 19ms/step - loss: 0.0363 - accuracy: 0.9894 - val_loss: 0.5517 - val_accuracy: 0.8891\n",
      "Epoch 38/80\n",
      "148/148 [==============================] - 3s 22ms/step - loss: 0.0258 - accuracy: 0.9926 - val_loss: 0.6952 - val_accuracy: 0.8642\n",
      "Epoch 39/80\n",
      "148/148 [==============================] - 3s 21ms/step - loss: 0.0320 - accuracy: 0.9909 - val_loss: 0.7270 - val_accuracy: 0.8681\n",
      "Epoch 40/80\n",
      "148/148 [==============================] - 3s 20ms/step - loss: 0.0533 - accuracy: 0.9838 - val_loss: 0.6041 - val_accuracy: 0.8738\n",
      "Epoch 41/80\n",
      "148/148 [==============================] - 3s 21ms/step - loss: 0.0239 - accuracy: 0.9940 - val_loss: 0.5647 - val_accuracy: 0.8776\n",
      "Epoch 42/80\n",
      "148/148 [==============================] - 3s 20ms/step - loss: 0.0125 - accuracy: 0.9962 - val_loss: 0.7012 - val_accuracy: 0.8642\n",
      "Epoch 43/80\n",
      "148/148 [==============================] - 3s 19ms/step - loss: 0.0246 - accuracy: 0.9917 - val_loss: 0.6525 - val_accuracy: 0.8910\n",
      "Epoch 44/80\n",
      "148/148 [==============================] - 3s 18ms/step - loss: 0.0109 - accuracy: 0.9972 - val_loss: 0.5959 - val_accuracy: 0.8910\n",
      "Epoch 45/80\n",
      "148/148 [==============================] - 3s 19ms/step - loss: 0.0070 - accuracy: 0.9987 - val_loss: 0.5834 - val_accuracy: 0.8929\n",
      "Epoch 46/80\n",
      "148/148 [==============================] - 3s 18ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.5684 - val_accuracy: 0.9025\n",
      "Epoch 47/80\n",
      "148/148 [==============================] - 3s 19ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.5848 - val_accuracy: 0.8891\n",
      "Epoch 48/80\n",
      "148/148 [==============================] - 4s 24ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.5851 - val_accuracy: 0.8967\n",
      "Epoch 49/80\n",
      "148/148 [==============================] - 3s 22ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.5684 - val_accuracy: 0.9044\n",
      "Epoch 50/80\n",
      "148/148 [==============================] - 4s 30ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.5978 - val_accuracy: 0.9025\n",
      "Epoch 51/80\n",
      "148/148 [==============================] - 5s 34ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.5694 - val_accuracy: 0.9025\n",
      "Epoch 52/80\n",
      "148/148 [==============================] - 4s 27ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.6094 - val_accuracy: 0.8948\n",
      "Epoch 53/80\n",
      "148/148 [==============================] - 6s 40ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.5802 - val_accuracy: 0.9044\n",
      "Epoch 54/80\n",
      "148/148 [==============================] - 4s 24ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.5995 - val_accuracy: 0.8967\n",
      "Epoch 55/80\n",
      "148/148 [==============================] - 3s 21ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.6173 - val_accuracy: 0.8967\n",
      "Epoch 56/80\n",
      "148/148 [==============================] - 3s 22ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.5908 - val_accuracy: 0.8987\n",
      "Epoch 57/80\n",
      "148/148 [==============================] - 3s 20ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.5909 - val_accuracy: 0.8929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/80\n",
      "148/148 [==============================] - 3s 20ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 0.5946 - val_accuracy: 0.9025\n",
      "Epoch 59/80\n",
      "148/148 [==============================] - 3s 19ms/step - loss: 0.0023 - accuracy: 0.9991 - val_loss: 0.6020 - val_accuracy: 0.9044\n",
      "Epoch 60/80\n",
      "148/148 [==============================] - 3s 18ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 0.5857 - val_accuracy: 0.9025\n",
      "Epoch 61/80\n",
      "148/148 [==============================] - 3s 20ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.6195 - val_accuracy: 0.8929\n",
      "Epoch 62/80\n",
      "148/148 [==============================] - 3s 20ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.6142 - val_accuracy: 0.9006\n",
      "Epoch 63/80\n",
      "148/148 [==============================] - 3s 18ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.6131 - val_accuracy: 0.9025\n",
      "Epoch 64/80\n",
      "148/148 [==============================] - 3s 22ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.6306 - val_accuracy: 0.9006\n",
      "Epoch 65/80\n",
      "148/148 [==============================] - 3s 23ms/step - loss: 0.0028 - accuracy: 0.9987 - val_loss: 0.6265 - val_accuracy: 0.8987\n",
      "Epoch 66/80\n",
      "148/148 [==============================] - 3s 23ms/step - loss: 0.0028 - accuracy: 0.9985 - val_loss: 0.6085 - val_accuracy: 0.8987\n",
      "Epoch 67/80\n",
      "148/148 [==============================] - 3s 20ms/step - loss: 0.0029 - accuracy: 0.9987 - val_loss: 0.6239 - val_accuracy: 0.9006\n",
      "Epoch 68/80\n",
      "148/148 [==============================] - 3s 20ms/step - loss: 0.0024 - accuracy: 0.9989 - val_loss: 0.6529 - val_accuracy: 0.8967\n",
      "Epoch 69/80\n",
      "148/148 [==============================] - 3s 23ms/step - loss: 0.0024 - accuracy: 0.9985 - val_loss: 0.6437 - val_accuracy: 0.8967\n",
      "Epoch 70/80\n",
      "148/148 [==============================] - 3s 21ms/step - loss: 0.0024 - accuracy: 0.9989 - val_loss: 0.6425 - val_accuracy: 0.8948\n",
      "Epoch 71/80\n",
      "148/148 [==============================] - 3s 23ms/step - loss: 0.0022 - accuracy: 0.9989 - val_loss: 0.6647 - val_accuracy: 0.8929\n",
      "Epoch 72/80\n",
      "148/148 [==============================] - 3s 20ms/step - loss: 0.2262 - accuracy: 0.9318 - val_loss: 0.7005 - val_accuracy: 0.8451\n",
      "Epoch 73/80\n",
      "148/148 [==============================] - 3s 22ms/step - loss: 0.1085 - accuracy: 0.9647 - val_loss: 0.5717 - val_accuracy: 0.8834\n",
      "Epoch 74/80\n",
      "148/148 [==============================] - 3s 24ms/step - loss: 0.0286 - accuracy: 0.9909 - val_loss: 0.6440 - val_accuracy: 0.8776\n",
      "Epoch 75/80\n",
      "148/148 [==============================] - 3s 20ms/step - loss: 0.0412 - accuracy: 0.9915 - val_loss: 0.5904 - val_accuracy: 0.8853\n",
      "Epoch 76/80\n",
      "148/148 [==============================] - 3s 20ms/step - loss: 0.0173 - accuracy: 0.9955 - val_loss: 0.5721 - val_accuracy: 0.8967\n",
      "Epoch 77/80\n",
      "148/148 [==============================] - 3s 22ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.5949 - val_accuracy: 0.9044\n",
      "Epoch 78/80\n",
      "148/148 [==============================] - 3s 23ms/step - loss: 0.0030 - accuracy: 0.9985 - val_loss: 0.5965 - val_accuracy: 0.9063\n",
      "Epoch 79/80\n",
      "148/148 [==============================] - 3s 21ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.5988 - val_accuracy: 0.9025\n",
      "Epoch 80/80\n",
      "148/148 [==============================] - 3s 20ms/step - loss: 0.0028 - accuracy: 0.9987 - val_loss: 0.6064 - val_accuracy: 0.9044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cddab5d340>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train_y = label_encoder.fit_transform(train_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Reshape the data for CNN input\n",
    "X_train = X_train.reshape((-1, 28, 28, 1))\n",
    "X_test = X_test.reshape((-1, 28, 28, 1))\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Define the CNN model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=80, batch_size=32, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b3f3e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8d0e190",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install protobuf==3.20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eef5e9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/cnn(digits+a-laa).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52ed3e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 6ms/step\n",
      "Convolutional Neural Network (CNN):\n",
      "Accuracy: 88.47%\n",
      "Precision: 89.57\n",
      "Recall: 88.47\n",
      "F1-score: 88.59\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "cnn_model=load_model(\"model/cnn(digits+a-laa).h5\")\n",
    "\n",
    "y_pred_probs = cnn_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy_cnn = accuracy_score(np.argmax(y_test, axis=1), y_pred) * 100\n",
    "precision_cnn = precision_score(np.argmax(y_test, axis=1), y_pred, average='weighted', zero_division=1)*100\n",
    "recall_cnn = recall_score(np.argmax(y_test, axis=1), y_pred, average='weighted')*100\n",
    "f1_cnn = f1_score(np.argmax(y_test, axis=1), y_pred, average='weighted')*100\n",
    "\n",
    "# Display the results\n",
    "print(\"Convolutional Neural Network (CNN):\")\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_cnn))\n",
    "print(\"Precision: {:.2f}\".format(precision_cnn))\n",
    "print(\"Recall: {:.2f}\".format(recall_cnn))\n",
    "print(\"F1-score: {:.2f}\".format(f1_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffc1b095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import pyscreenshot as ImageGrab\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "model = load_model(\"model/cnn(digits+a-laa).h5\")  # Update with the correct path to your Kannada digit and alphabet recognition model\n",
    "\n",
    "images_folder = \"img/\"\n",
    "\n",
    "character_actual = None  # Variable to store the actual digit or alphabet drawn by the user\n",
    "\n",
    "while True:\n",
    "    img = ImageGrab.grab(bbox=(60, 170, 400, 500))  # Adjust the coordinates to capture the appropriate region\n",
    "\n",
    "    img.save(images_folder + \"img.png\")\n",
    "    im = cv2.imread(images_folder + \"img.png\")\n",
    "    im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    im_gray = cv2.GaussianBlur(im_gray, (15, 15), 0)\n",
    "\n",
    "    # Threshold the image\n",
    "    ret, im_th = cv2.threshold(im_gray, 100, 255, cv2.THRESH_BINARY)\n",
    "    roi = cv2.resize(im_th, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    rows, cols = roi.shape\n",
    "\n",
    "    X = []\n",
    "\n",
    "    # Add pixel one by one into the data array\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            k = roi[i, j]\n",
    "            if k > 100:\n",
    "                k = 1\n",
    "            else:\n",
    "                k = 0\n",
    "            X.append(k)\n",
    "\n",
    "    X = np.array(X)  # Convert X to a NumPy array\n",
    "    if not any(X):\n",
    "        character = \"noCharVisible\"\n",
    "    else:\n",
    "        prediction = model.predict(X.reshape(1, 28, 28, 1))\n",
    "        predicted_class_index = np.argmax(prediction)  # Find the index of the maximum value\n",
    "\n",
    "    # Inverse transform the predicted class index to get the corresponding label\n",
    "        character = label_encoder.inverse_transform([predicted_class_index])[0]\n",
    "\n",
    "    # Draw prediction and accuracy on the image\n",
    "    cv2.putText(im, \"Prediction: \" + str(character), (20, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.startWindowThread()\n",
    "    cv2.namedWindow(\"Result\")\n",
    "    cv2.imshow(\"Result\", im)\n",
    "\n",
    "    # Wait for user input to set the actual digit or alphabet\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:  # If ESC key is pressed, exit the loop\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2753821f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

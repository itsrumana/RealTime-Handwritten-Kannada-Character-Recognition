{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d306d1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import glob\n",
    "\n",
    "# Parent folder path containing the digit and alphabet folders\n",
    "parent_folder_path = \"C:/Users/Rumana/Desktop/HandWritten_Kannada/captured_images\"\n",
    "\n",
    "# Define the labels for digits and alphabets\n",
    "digit_labels = list(range(10))\n",
    "alphabet_labels = ['a', 'aaa', 'e', 'eee', 'u', 'uuu', 'ru', 'ye', 'yeee', 'ai', 'o', 'ooo', 'oww', 'am', 'aha']\n",
    "\n",
    "# Define the header for the CSV file\n",
    "header = [\"label\"]\n",
    "for i in range(0, 784):\n",
    "    header.append(\"pixel\" + str(i))\n",
    "\n",
    "with open('kan_data.csv', 'a') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "\n",
    "# Load the captured images and preprocess them\n",
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "# Process digits and alphabets\n",
    "for label in digit_labels + alphabet_labels:\n",
    "    dirList = glob.glob(os.path.join(parent_folder_path, str(label), \"*.png\"))\n",
    "\n",
    "    for img_path in dirList:\n",
    "        im = cv2.imread(img_path)\n",
    "        im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "        im_gray = cv2.GaussianBlur(im_gray, (15, 15), 0)\n",
    "        roi = cv2.resize(im_gray, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        data = []\n",
    "        data.append(label)\n",
    "\n",
    "        # Flatten the image data\n",
    "        flattened_image = roi.flatten() / 255.0\n",
    "        data.extend(flattened_image)\n",
    "\n",
    "        train_x.append(flattened_image)\n",
    "        train_y.append(label)\n",
    "\n",
    "        with open('kan_data.csv', 'a') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(data)\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "\n",
    "# Save the training dataset as numpy arrays\n",
    "np.save(\"C:/Users/Rumana/Desktop/HandWritten_Kannada/captured_images/train_x.npy\", train_x)\n",
    "np.save(\"C:/Users/Rumana/Desktop/HandWritten_Kannada/captured_images/train_y.npy\", train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6b144b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5357</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>ru</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1607843137254902</td>\n",
       "      <td>0.01568627450980392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1607843137254902</td>\n",
       "      <td>0.01568627450980392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>ye</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2418</th>\n",
       "      <td>aha</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4628 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label pixel0 pixel1 pixel2 pixel3 pixel4 pixel5 pixel6 pixel7 pixel8  \\\n",
       "5357     3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "779      7      0      0      0      0      0      0      0      0      0   \n",
       "1267     e      0      0      0      0      0      0      0      0      0   \n",
       "682      6      0      0      0      0      0      0      0      0      0   \n",
       "1297     e      0      0      0      0      0      0      0      0      0   \n",
       "...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "1665    ru      0      0      0      0      0      0      0      0      0   \n",
       "5725     7    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "5995     9    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1706    ye      0      0      0      0      0      0      0      0      0   \n",
       "2418   aha      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "      ...            pixel774             pixel775 pixel776 pixel777 pixel778  \\\n",
       "5357  ...                 0.0                  0.0      0.0      0.0      0.0   \n",
       "779   ...                   0                    0        0        0        0   \n",
       "1267  ...                   0                    0        0        0        0   \n",
       "682   ...                   0                    0        0        0        0   \n",
       "1297  ...                   0                    0        0        0        0   \n",
       "...   ...                 ...                  ...      ...      ...      ...   \n",
       "1665  ...                   0                    0        0        0        0   \n",
       "5725  ...  0.1607843137254902  0.01568627450980392      0.0      0.0      0.0   \n",
       "5995  ...  0.1607843137254902  0.01568627450980392      0.0      0.0      0.0   \n",
       "1706  ...                   0                    0        0        0        0   \n",
       "2418  ...                   0                    0        0        0        0   \n",
       "\n",
       "     pixel779 pixel780 pixel781 pixel782 pixel783  \n",
       "5357      0.0      0.0      0.0      0.0      0.0  \n",
       "779         0        0        0        0        0  \n",
       "1267        0        0        0        0        0  \n",
       "682         0        0        0        0        0  \n",
       "1297        0        0        0        0        0  \n",
       "...       ...      ...      ...      ...      ...  \n",
       "1665        0        0        0        0        0  \n",
       "5725      0.0      0.0      0.0      0.0      0.0  \n",
       "5995      0.0      0.0      0.0      0.0      0.0  \n",
       "1706        0        0        0        0        0  \n",
       "2418        0        0        0        0        0  \n",
       "\n",
       "[4628 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "data  =pd.read_csv('kan_data.csv',dtype=str)\n",
    "# Identify duplicates\n",
    "duplicates = data[data.duplicated()]\n",
    "\n",
    "# Remove duplicates\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "# Shuffle the dataset\n",
    "data = shuffle(data)\n",
    "\n",
    "data=shuffle(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f517568b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = data.drop([\"label\"],axis=1)\n",
    "Y = data[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d23287a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_shuffled_images(images, labels, rows, cols):\n",
    "    # Combine images and labels into a single array for shuffling\n",
    "    combined_data = list(zip(images, labels))\n",
    "    np.random.shuffle(combined_data)\n",
    "    \n",
    "    # Unpack the shuffled data\n",
    "    shuffled_images, shuffled_labels = zip(*combined_data)\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(10, 10))\n",
    "\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            idx = i * cols + j\n",
    "            img = shuffled_images[idx].reshape(28, 28).astype(float)  # Convert to float\n",
    "            label = shuffled_labels[idx]\n",
    "\n",
    "            axes[i, j].imshow(img, cmap='gray')\n",
    "            axes[i, j].set_title(f\"Label: {label}\")\n",
    "            axes[i, j].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Specify the number of rows and columns for the grid\n",
    "num_rows = 3\n",
    "num_cols = 4\n",
    "\n",
    "# Assuming X is a DataFrame containing image data and Y is a Series containing labels\n",
    "# You can adapt this based on your specific data structure\n",
    "# Display a shuffled set of images from your dataset\n",
    "display_shuffled_images(X.values, Y, num_rows, num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85bf35c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Load the training dataset\n",
    "train_x = np.load(\"C:/Users/Rumana/Desktop/HandWritten_Kannada/captured_images/train_x.npy\")\n",
    "train_y = np.load(\"C:/Users/Rumana/Desktop/HandWritten_Kannada/captured_images/train_y.npy\")\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9abc97",
   "metadata": {},
   "source": [
    "# support vector classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "255e962c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', random_state=6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', random_state=6)\n",
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a3eba46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/svm(digits+a-aha)']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(svm_model,\"model/svm(digits+a-aha)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f34cdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.26%\n",
      "Precision: 87.39%\n",
      "Recall: 85.26%\n",
      "F1 Score: 85.43%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import joblib\n",
    "\n",
    "# Load the trained SVC model\n",
    "svc_model = joblib.load(\"model/svm(digits+a-aha)\")\n",
    "\n",
    "# Assuming X_test_imputed and test_y are correctly loaded and preprocessed\n",
    "predictions = svc_model.predict(X_test)\n",
    "\n",
    "# Evaluate metrics\n",
    "accuracy = accuracy_score(y_test, predictions) * 100\n",
    "precision = precision_score(y_test, predictions, average='weighted') * 100\n",
    "recall = recall_score(y_test, predictions, average='weighted') * 100\n",
    "f1 = f1_score(y_test, predictions, average='weighted') * 100\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}%\")\n",
    "print(f\"Recall: {recall:.2f}%\")\n",
    "print(f\"F1 Score: {f1:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be53f0d2",
   "metadata": {},
   "source": [
    "# K-nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e40f22ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/knn(digits+a-aha)']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import joblib\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(knn,\"model/knn(digits+a-aha)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4b944fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.27%\n",
      "Precision: 83.88%\n",
      "Recall: 81.27%\n",
      "F1 Score: 81.51%\n"
     ]
    }
   ],
   "source": [
    "knn_model = joblib.load(\"model/knn(digits+a-aha)\")\n",
    "\n",
    "# Assuming X_test_imputed and test_y are correctly loaded and preprocessed\n",
    "predictions = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate metrics\n",
    "accuracy = accuracy_score(y_test, predictions) * 100\n",
    "precision = precision_score(y_test, predictions, average='weighted') * 100\n",
    "recall = recall_score(y_test, predictions, average='weighted') * 100\n",
    "f1 = f1_score(y_test, predictions, average='weighted') * 100\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}%\")\n",
    "print(f\"Recall: {recall:.2f}%\")\n",
    "print(f\"F1 Score: {f1:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672b659c",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ec87064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "64/64 [==============================] - 3s 31ms/step - loss: 2.4708 - accuracy: 0.2820 - val_loss: 1.4728 - val_accuracy: 0.5156\n",
      "Epoch 2/80\n",
      "64/64 [==============================] - 1s 23ms/step - loss: 1.0122 - accuracy: 0.7047 - val_loss: 0.7628 - val_accuracy: 0.7867\n",
      "Epoch 3/80\n",
      "64/64 [==============================] - 2s 26ms/step - loss: 0.6392 - accuracy: 0.8020 - val_loss: 0.6367 - val_accuracy: 0.8267\n",
      "Epoch 4/80\n",
      "64/64 [==============================] - 1s 23ms/step - loss: 0.4364 - accuracy: 0.8726 - val_loss: 0.4848 - val_accuracy: 0.8578\n",
      "Epoch 5/80\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.3132 - accuracy: 0.9032 - val_loss: 0.4094 - val_accuracy: 0.8711\n",
      "Epoch 6/80\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.2424 - accuracy: 0.9170 - val_loss: 0.4322 - val_accuracy: 0.8400\n",
      "Epoch 7/80\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.1673 - accuracy: 0.9526 - val_loss: 0.3431 - val_accuracy: 0.9022\n",
      "Epoch 8/80\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.1251 - accuracy: 0.9575 - val_loss: 0.3063 - val_accuracy: 0.9111\n",
      "Epoch 9/80\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 0.0954 - accuracy: 0.9704 - val_loss: 0.3029 - val_accuracy: 0.9111\n",
      "Epoch 10/80\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 0.1090 - accuracy: 0.9615 - val_loss: 0.2457 - val_accuracy: 0.9378\n",
      "Epoch 11/80\n",
      "64/64 [==============================] - 2s 36ms/step - loss: 0.0570 - accuracy: 0.9842 - val_loss: 0.2565 - val_accuracy: 0.9200\n",
      "Epoch 12/80\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 0.0379 - accuracy: 0.9877 - val_loss: 0.2567 - val_accuracy: 0.9333\n",
      "Epoch 13/80\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.0367 - accuracy: 0.9881 - val_loss: 0.1911 - val_accuracy: 0.9511\n",
      "Epoch 14/80\n",
      "64/64 [==============================] - 2s 24ms/step - loss: 0.0247 - accuracy: 0.9926 - val_loss: 0.2058 - val_accuracy: 0.9289\n",
      "Epoch 15/80\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.0382 - accuracy: 0.9867 - val_loss: 0.2852 - val_accuracy: 0.9067\n",
      "Epoch 16/80\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.0891 - accuracy: 0.9699 - val_loss: 0.3113 - val_accuracy: 0.9111\n",
      "Epoch 17/80\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.0209 - accuracy: 0.9960 - val_loss: 0.2757 - val_accuracy: 0.9422\n",
      "Epoch 18/80\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.2584 - val_accuracy: 0.9467\n",
      "Epoch 19/80\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2593 - val_accuracy: 0.9556\n",
      "Epoch 20/80\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.2627 - val_accuracy: 0.9467\n",
      "Epoch 21/80\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.0157 - accuracy: 0.9956 - val_loss: 0.3116 - val_accuracy: 0.9378\n",
      "Epoch 22/80\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 0.0177 - accuracy: 0.9941 - val_loss: 0.2968 - val_accuracy: 0.9378\n",
      "Epoch 23/80\n",
      "64/64 [==============================] - 1s 21ms/step - loss: 0.0124 - accuracy: 0.9960 - val_loss: 0.2740 - val_accuracy: 0.9244\n",
      "Epoch 24/80\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2201 - val_accuracy: 0.9511\n",
      "Epoch 25/80\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 9.5841e-04 - accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 0.9467\n",
      "Epoch 26/80\n",
      "64/64 [==============================] - 2s 26ms/step - loss: 5.2972e-04 - accuracy: 1.0000 - val_loss: 0.2174 - val_accuracy: 0.9600\n",
      "Epoch 27/80\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 4.4589e-04 - accuracy: 1.0000 - val_loss: 0.2214 - val_accuracy: 0.9511\n",
      "Epoch 28/80\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 3.5422e-04 - accuracy: 1.0000 - val_loss: 0.2229 - val_accuracy: 0.9600\n",
      "Epoch 29/80\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 3.1442e-04 - accuracy: 1.0000 - val_loss: 0.2258 - val_accuracy: 0.9556\n",
      "Epoch 30/80\n",
      "64/64 [==============================] - 2s 29ms/step - loss: 2.8812e-04 - accuracy: 1.0000 - val_loss: 0.2271 - val_accuracy: 0.9600\n",
      "Epoch 31/80\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 2.5510e-04 - accuracy: 1.0000 - val_loss: 0.2278 - val_accuracy: 0.9556\n",
      "Epoch 32/80\n",
      "64/64 [==============================] - 2s 24ms/step - loss: 2.2955e-04 - accuracy: 1.0000 - val_loss: 0.2294 - val_accuracy: 0.9556\n",
      "Epoch 33/80\n",
      "64/64 [==============================] - 2s 24ms/step - loss: 2.1392e-04 - accuracy: 1.0000 - val_loss: 0.2308 - val_accuracy: 0.9556\n",
      "Epoch 34/80\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 1.9724e-04 - accuracy: 1.0000 - val_loss: 0.2323 - val_accuracy: 0.9511\n",
      "Epoch 35/80\n",
      "64/64 [==============================] - 2s 25ms/step - loss: 1.9580e-04 - accuracy: 1.0000 - val_loss: 0.2338 - val_accuracy: 0.9556\n",
      "Epoch 36/80\n",
      "64/64 [==============================] - 2s 24ms/step - loss: 1.6724e-04 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 0.9556\n",
      "Epoch 37/80\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 1.5631e-04 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9511\n",
      "Epoch 38/80\n",
      "64/64 [==============================] - 1s 21ms/step - loss: 1.4764e-04 - accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 0.9511\n",
      "Epoch 39/80\n",
      "64/64 [==============================] - 1s 21ms/step - loss: 1.3776e-04 - accuracy: 1.0000 - val_loss: 0.2379 - val_accuracy: 0.9556\n",
      "Epoch 40/80\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 1.2728e-04 - accuracy: 1.0000 - val_loss: 0.2388 - val_accuracy: 0.9556\n",
      "Epoch 41/80\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 1.2199e-04 - accuracy: 1.0000 - val_loss: 0.2391 - val_accuracy: 0.9556\n",
      "Epoch 42/80\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 1.1314e-04 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9467\n",
      "Epoch 43/80\n",
      "64/64 [==============================] - 1s 19ms/step - loss: 1.0716e-04 - accuracy: 1.0000 - val_loss: 0.2427 - val_accuracy: 0.9467\n",
      "Epoch 44/80\n",
      "64/64 [==============================] - 2s 24ms/step - loss: 1.0196e-04 - accuracy: 1.0000 - val_loss: 0.2421 - val_accuracy: 0.9511\n",
      "Epoch 45/80\n",
      "64/64 [==============================] - 2s 28ms/step - loss: 9.6176e-05 - accuracy: 1.0000 - val_loss: 0.2453 - val_accuracy: 0.9467\n",
      "Epoch 46/80\n",
      "64/64 [==============================] - 2s 24ms/step - loss: 9.1569e-05 - accuracy: 1.0000 - val_loss: 0.2442 - val_accuracy: 0.9556\n",
      "Epoch 47/80\n",
      "64/64 [==============================] - 2s 25ms/step - loss: 8.5876e-05 - accuracy: 1.0000 - val_loss: 0.2464 - val_accuracy: 0.9556\n",
      "Epoch 48/80\n",
      "64/64 [==============================] - 2s 31ms/step - loss: 8.1729e-05 - accuracy: 1.0000 - val_loss: 0.2471 - val_accuracy: 0.9467\n",
      "Epoch 49/80\n",
      "64/64 [==============================] - 1s 23ms/step - loss: 7.8649e-05 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 0.9467\n",
      "Epoch 50/80\n",
      "64/64 [==============================] - 2s 29ms/step - loss: 7.4655e-05 - accuracy: 1.0000 - val_loss: 0.2483 - val_accuracy: 0.9511\n",
      "Epoch 51/80\n",
      "64/64 [==============================] - 2s 31ms/step - loss: 7.1631e-05 - accuracy: 1.0000 - val_loss: 0.2506 - val_accuracy: 0.9511\n",
      "Epoch 52/80\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 6.6661e-05 - accuracy: 1.0000 - val_loss: 0.2516 - val_accuracy: 0.9467\n",
      "Epoch 53/80\n",
      "64/64 [==============================] - 2s 26ms/step - loss: 6.4357e-05 - accuracy: 1.0000 - val_loss: 0.2524 - val_accuracy: 0.9511\n",
      "Epoch 54/80\n",
      "64/64 [==============================] - 2s 28ms/step - loss: 6.1546e-05 - accuracy: 1.0000 - val_loss: 0.2549 - val_accuracy: 0.9467\n",
      "Epoch 55/80\n",
      "64/64 [==============================] - 2s 24ms/step - loss: 5.7864e-05 - accuracy: 1.0000 - val_loss: 0.2544 - val_accuracy: 0.9511\n",
      "Epoch 56/80\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 5.5525e-05 - accuracy: 1.0000 - val_loss: 0.2559 - val_accuracy: 0.9511\n",
      "Epoch 57/80\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 5.2535e-05 - accuracy: 1.0000 - val_loss: 0.2566 - val_accuracy: 0.9511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/80\n",
      "64/64 [==============================] - 2s 25ms/step - loss: 5.0225e-05 - accuracy: 1.0000 - val_loss: 0.2576 - val_accuracy: 0.9511\n",
      "Epoch 59/80\n",
      "64/64 [==============================] - 1s 20ms/step - loss: 4.7939e-05 - accuracy: 1.0000 - val_loss: 0.2576 - val_accuracy: 0.9511\n",
      "Epoch 60/80\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 4.5670e-05 - accuracy: 1.0000 - val_loss: 0.2599 - val_accuracy: 0.9467\n",
      "Epoch 61/80\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 4.4365e-05 - accuracy: 1.0000 - val_loss: 0.2596 - val_accuracy: 0.9511\n",
      "Epoch 62/80\n",
      "64/64 [==============================] - 2s 24ms/step - loss: 4.2435e-05 - accuracy: 1.0000 - val_loss: 0.2620 - val_accuracy: 0.9467\n",
      "Epoch 63/80\n",
      "64/64 [==============================] - 1s 21ms/step - loss: 4.0383e-05 - accuracy: 1.0000 - val_loss: 0.2626 - val_accuracy: 0.9511\n",
      "Epoch 64/80\n",
      "64/64 [==============================] - 2s 25ms/step - loss: 3.8351e-05 - accuracy: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.9511\n",
      "Epoch 65/80\n",
      "64/64 [==============================] - 2s 24ms/step - loss: 3.6855e-05 - accuracy: 1.0000 - val_loss: 0.2647 - val_accuracy: 0.9511\n",
      "Epoch 66/80\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 3.5274e-05 - accuracy: 1.0000 - val_loss: 0.2653 - val_accuracy: 0.9511\n",
      "Epoch 67/80\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 3.4100e-05 - accuracy: 1.0000 - val_loss: 0.2654 - val_accuracy: 0.9511\n",
      "Epoch 68/80\n",
      "64/64 [==============================] - 2s 30ms/step - loss: 3.2578e-05 - accuracy: 1.0000 - val_loss: 0.2665 - val_accuracy: 0.9467\n",
      "Epoch 69/80\n",
      "64/64 [==============================] - 2s 25ms/step - loss: 3.1580e-05 - accuracy: 1.0000 - val_loss: 0.2675 - val_accuracy: 0.9467\n",
      "Epoch 70/80\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 2.9996e-05 - accuracy: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.9511\n",
      "Epoch 71/80\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 2.9007e-05 - accuracy: 1.0000 - val_loss: 0.2700 - val_accuracy: 0.9511\n",
      "Epoch 72/80\n",
      "64/64 [==============================] - 2s 27ms/step - loss: 2.7780e-05 - accuracy: 1.0000 - val_loss: 0.2699 - val_accuracy: 0.9511\n",
      "Epoch 73/80\n",
      "64/64 [==============================] - 2s 25ms/step - loss: 2.6532e-05 - accuracy: 1.0000 - val_loss: 0.2707 - val_accuracy: 0.9467\n",
      "Epoch 74/80\n",
      "64/64 [==============================] - 1s 23ms/step - loss: 2.5385e-05 - accuracy: 1.0000 - val_loss: 0.2718 - val_accuracy: 0.9467\n",
      "Epoch 75/80\n",
      "64/64 [==============================] - 2s 24ms/step - loss: 2.4393e-05 - accuracy: 1.0000 - val_loss: 0.2721 - val_accuracy: 0.9511\n",
      "Epoch 76/80\n",
      "64/64 [==============================] - 2s 25ms/step - loss: 2.3764e-05 - accuracy: 1.0000 - val_loss: 0.2734 - val_accuracy: 0.9511\n",
      "Epoch 77/80\n",
      "64/64 [==============================] - 2s 24ms/step - loss: 2.2747e-05 - accuracy: 1.0000 - val_loss: 0.2746 - val_accuracy: 0.9511\n",
      "Epoch 78/80\n",
      "64/64 [==============================] - 1s 21ms/step - loss: 2.1797e-05 - accuracy: 1.0000 - val_loss: 0.2752 - val_accuracy: 0.9511\n",
      "Epoch 79/80\n",
      "64/64 [==============================] - 2s 23ms/step - loss: 2.0825e-05 - accuracy: 1.0000 - val_loss: 0.2754 - val_accuracy: 0.9511\n",
      "Epoch 80/80\n",
      "64/64 [==============================] - 1s 21ms/step - loss: 2.0161e-05 - accuracy: 1.0000 - val_loss: 0.2765 - val_accuracy: 0.9511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21581982700>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train_y = label_encoder.fit_transform(train_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Reshape the data for CNN input\n",
    "X_train = X_train.reshape((-1, 28, 28, 1))\n",
    "X_test = X_test.reshape((-1, 28, 28, 1))\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Define the CNN model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=80, batch_size=32, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a54162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/cnn(digits+a-aha).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e9acbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 6ms/step\n",
      "Convolutional Neural Network (CNN):\n",
      "Accuracy: 93.63%\n",
      "Precision: 94.16\n",
      "Recall: 93.63\n",
      "F1-score: 93.65\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "cnn_model=load_model(\"model/cnn(digits+a-aha).h5\")\n",
    "\n",
    "y_pred_probs = cnn_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy_cnn = accuracy_score(np.argmax(y_test, axis=1), y_pred) * 100\n",
    "precision_cnn = precision_score(np.argmax(y_test, axis=1), y_pred, average='weighted', zero_division=1)*100\n",
    "recall_cnn = recall_score(np.argmax(y_test, axis=1), y_pred, average='weighted')*100\n",
    "f1_cnn = f1_score(np.argmax(y_test, axis=1), y_pred, average='weighted')*100\n",
    "\n",
    "# Display the results\n",
    "print(\"Convolutional Neural Network (CNN):\")\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_cnn))\n",
    "print(\"Precision: {:.2f}\".format(precision_cnn))\n",
    "print(\"Recall: {:.2f}\".format(recall_cnn))\n",
    "print(\"F1-score: {:.2f}\".format(f1_cnn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33d29fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import pyscreenshot as ImageGrab\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "model = load_model(\"model/cnn(digits+a-aha).h5\")  # Update with the correct path to your Kannada digit and alphabet recognition model\n",
    "\n",
    "images_folder = \"img/\"\n",
    "\n",
    "character_actual = None  # Variable to store the actual digit or alphabet drawn by the user\n",
    "\n",
    "while True:\n",
    "    img = ImageGrab.grab(bbox=(60, 170, 400, 500))  # Adjust the coordinates to capture the appropriate region\n",
    "\n",
    "    img.save(images_folder + \"img.png\")\n",
    "    im = cv2.imread(images_folder + \"img.png\")\n",
    "    im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    im_gray = cv2.GaussianBlur(im_gray, (15, 15), 0)\n",
    "\n",
    "    # Threshold the image\n",
    "    ret, im_th = cv2.threshold(im_gray, 100, 255, cv2.THRESH_BINARY)\n",
    "    roi = cv2.resize(im_th, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    rows, cols = roi.shape\n",
    "\n",
    "    X = []\n",
    "\n",
    "    # Add pixel one by one into the data array\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            k = roi[i, j]\n",
    "            if k > 100:\n",
    "                k = 1\n",
    "            else:\n",
    "                k = 0\n",
    "            X.append(k)\n",
    "\n",
    "    X = np.array(X)  # Convert X to a NumPy array\n",
    "    if not any(X):\n",
    "        character = \"noCharVisible\"\n",
    "    else:\n",
    "        prediction = model.predict(X.reshape(1, 28, 28, 1))\n",
    "        predicted_class_index = np.argmax(prediction)  # Find the index of the maximum value\n",
    "\n",
    "    # Inverse transform the predicted class index to get the corresponding label\n",
    "        character = label_encoder.inverse_transform([predicted_class_index])[0]\n",
    "\n",
    "    # Draw prediction and accuracy on the image\n",
    "    cv2.putText(im, \"Prediction: \" + str(character), (20, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.startWindowThread()\n",
    "    cv2.namedWindow(\"Result\")\n",
    "    cv2.imshow(\"Result\", im)\n",
    "\n",
    "    # Wait for user input to set the actual digit or alphabet\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:  # If ESC key is pressed, exit the loop\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b107e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
